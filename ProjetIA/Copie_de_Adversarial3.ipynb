{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YroMaxFATRHG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "cuda = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiY3BiAiTRHK"
      },
      "source": [
        "## From adversarial examples to training robust models\n",
        "\n",
        "In the previous notebooks, we focused on methods for solving the maximization problem over perturbations; that is, to finding the solution to the problem\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\maximize}{maximize}\n",
        "\\maximize_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "\n",
        "In this notebook, we will focus on training a robust classifier. More precisly, we aim at solving following minimization problem, namely Adversarial Training:\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\minimize_\\theta \\frac{1}{|S|} \\sum_{x,y \\in S} \\max_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "The order of the min-max operations is important here.  Specially, the max is inside the minimization, meaning that the adversary (trying to maximize the loss) gets to \"move\" _second_.  We assume, essentially, that the adversary has full knowledge of the classifier parameters $\\theta$, and that they get to specialize their attack to whatever parameters we have chosen in the outer minimization. The goal of the robust optimization formulation, therefore, is to ensure that the model cannot be attacked _even if_ the adversary has full knowledge of the model.  Of course, in practice we may want to make assumptions about the power of the adversary but it can be difficult to pin down a precise definition of what we mean by the \"power\" of the adversary, so extra care should be taken in evaluating models against possible \"realistic\" adversaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMXb08jTRHL"
      },
      "source": [
        "## Exercice 1\n",
        "1. Train a robust classifier using Adversarial Training with a specific norm\n",
        "2. Evaluate your classifier on natural and adversarial examples crafted with the norm of the training and other norms\n",
        "3. Make an analysis and conclude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w21alYjaTRHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85533241-704c-49d9-e2ed-201f2e8353f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./docs/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9109268.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./docs/cifar-10-python.tar.gz to ./docs\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# load CIFAR10 dataset\n",
        "def load_cifar(split, batch_size):\n",
        "  train = True if split == 'train' else False\n",
        "  dataset = datasets.CIFAR10(\"./docs\", train=split, download=True, transform=transforms.ToTensor())\n",
        "  return DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = load_cifar('train', batch_size)\n",
        "test_loader = load_cifar('test', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e5awbg2Qst1h"
      },
      "outputs": [],
      "source": [
        "class ConvModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ConvModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 3, padding=1) # 3 input channels, 6 output channels (doit être sup a input), 3x3 kernel\n",
        "    self.pool = nn.MaxPool2d(2) # 2x2 kernel\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, padding=1) # 6 input channels, 16 output channels, 3x3 kernel\n",
        "    self.fc1 = nn.Linear(16 * 8 * 8, 120) # 16x8x8 input features, 120 output features\n",
        "    self.fc2 = nn.Linear(120, 84) # 120 input features, 84 output features\n",
        "    self.fc3 = nn.Linear(84, 10) # 84 input features, 10 output features\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    #print(x.size())\n",
        "    x = x.view(-1, 16 * 8 * 8)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j9B-ea_dTRHO"
      },
      "outputs": [],
      "source": [
        "class FastGradientSignMethod:\n",
        "\n",
        "  def __init__(self, model, eps):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.eps = eps\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "  def compute(self, x, y):\n",
        "    \"\"\" Construct FGSM adversarial perturbation for examples x\"\"\"\n",
        "    x.requires_grad = True\n",
        "    y_pred = self.model(x)\n",
        "    loss = self.loss(y_pred, y)\n",
        "    loss.backward()\n",
        "    grad = x.grad.data\n",
        "    grad = grad.sign()\n",
        "    return self.eps * grad\n",
        "    #delta = torch.zeros_like(x, requires_grad=True)\n",
        "    # Use variable.grad.detach() to retreive the gradient with respect to a loss\n",
        "\n",
        "eps = 0.007 # define eps here\n",
        "fgsm = FastGradientSignMethod(model,eps)\n",
        "\n",
        "class ProjectedGradientDescent:\n",
        "\n",
        "  def __init__(self, model, eps, alpha, num_iter):\n",
        "    self.model = model\n",
        "    self.eps = eps\n",
        "    self.alpha = alpha #le pas\n",
        "    self.num_iter = num_iter #nb iteration\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "  def compute(self, x, y):\n",
        "    \"\"\" Construct PGD adversarial pertubration on the examples x.\"\"\"\n",
        "    delta = torch.zeros_like(x, requires_grad=True)\n",
        "    for _ in range(self.num_iter):\n",
        "      y_pred = self.model(x+delta)\n",
        "      loss = self.loss(y_pred, y)\n",
        "      loss.backward()\n",
        "      grad = delta.grad\n",
        "      delta.data = delta.data + self.alpha * grad.detach().sign()\n",
        "      delta.data = torch.clamp(delta, -self.eps, self.eps) #projection sur le cercle\n",
        "      #delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n",
        "alpha = 1e-2\n",
        "pgd = ProjectedGradientDescent(model, eps, alpha, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZJM3XkrFTRHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ca76a3-a4b3-496b-8c07-f3fb669b629b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.64851740837097"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def adversarial_train_model(model, criterion, optimizer, loader, attack):\n",
        "  \"\"\"Function to train the model\"\"\"\n",
        "  train_loss = 0.\n",
        "  model.train()\n",
        "  epochs = 10\n",
        "\n",
        "  for e in range(epochs):\n",
        "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "      if cuda:\n",
        "       imgs, labels = imgs.cuda(), labels.cuda()\n",
        "      # clear the gradients of all optimized variables\n",
        "      optimizer.zero_grad()\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      img_attack = imgs + attack.compute(imgs, labels)\n",
        "      output = model(img_attack)\n",
        "      # calculate the batch loss\n",
        "      loss = criterion(output, labels)\n",
        "      # backward pass: compute gradient of the loss with respect to model parameters\n",
        "      loss.backward()\n",
        "      # perform a single optimization step (parameter update)\n",
        "      optimizer.step()\n",
        "      # update training loss\n",
        "      train_loss += loss.item()*imgs.size(0)\n",
        "\n",
        "  return train_loss / len(train_loader.dataset)\n",
        "\n",
        "# adverserial training with PGD\n",
        "model = ConvModel()\n",
        "if cuda:\n",
        "  model = model.cuda()\n",
        "\n",
        "# define your loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "opt = optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# define the attack\n",
        "attack = fgsm\n",
        "\n",
        "adversarial_train_model(model, criterion, opt, train_loader, attack)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model depending on the attack\n",
        "\n",
        "model1=ConvModel()\n",
        "if cuda:\n",
        "  model1 = model1.cuda()\n",
        "\n",
        "model2=ConvModel()\n",
        "if cuda:\n",
        "  model2 = model2.cuda()\n",
        "\n",
        "def adversarial_train_model_2(model, criterion, optimizer, loader, attack):\n",
        "\n",
        " train_loss = 0.\n",
        " model.train()\n",
        " epochs = 10\n",
        " k=3\n",
        "\n",
        " for e in range(epochs):\n",
        "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "      if cuda:\n",
        "       imgs, labels = imgs.cuda(), labels.cuda()\n",
        "       if batch_idx % k == 0:\n",
        "          delta = attack.compute(imgs, labels)\n",
        "          adv_imgs = torch.clamp(imgs + delta, min=0, max=1)\n",
        "          output = model(adv_imgs)\n",
        "       else:\n",
        "          output = model(imgs)\n",
        "\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        " return train_loss / len(loader.dataset)\n",
        ""
      ],
      "metadata": {
        "id": "CUHaqFQ_IYv8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2C3VJ0qtTRHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877246e8-dffd-426a-9e80-53cda1ded824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on testset: 0.1000\n",
            "accuracy on testset: 0.1000\n"
          ]
        }
      ],
      "source": [
        "def eval_model(model, loader, attack=None):\n",
        "  \"\"\"Function to evaluate your model on a specific loader\"\"\"\n",
        "  accuracy = 0.\n",
        "  n_inputs = 0.\n",
        "  for n_batch, (imgs, labels) in enumerate(loader):\n",
        "    if cuda:\n",
        "      imgs, labels = imgs.cuda(), labels.cuda()\n",
        "    if attack is None:\n",
        "      outputs = model(imgs)\n",
        "    else:\n",
        "      delta = attack.compute(imgs, labels)\n",
        "      adv = imgs + delta\n",
        "      outputs = model(adv)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy += predicted.eq(labels.data).cpu().sum().numpy()\n",
        "    n_inputs += imgs.shape[0]\n",
        "  accuracy /= n_inputs\n",
        "  print('accuracy on testset: {:.4f}'.format(accuracy))\n",
        "\n",
        "attack = fgsm\n",
        "eval_model(model, test_loader)\n",
        "eval_model(model, test_loader, attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3vrKZ7eTRHZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqDnEtU9TRHb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}