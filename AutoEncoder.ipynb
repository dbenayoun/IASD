{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder (**AE**) is a special type of neural network that is trained to copy its input to its output. For example, given an image of a handwritten digit, an autoencoder first encodes the image into a lower dimensional latent representation, then decodes the latent representation back to an image. An autoencoder learns to compress the data while minimizing the reconstruction error. This is an example of unsupervised learning. Autoencoder can be used to learn representation (the by product of the encoder), and to detect anomalies.  \n",
    "\n",
    "An autoencoder consists in two blocks: \n",
    "- the encoder projects the input in a latent space of \"reduced\" dimension (in comparison with the input). \n",
    "- the decoder maps some latent representation back in the input space. \n",
    "\n",
    "Basically, if you consider an input $\\mathbf{x}$ : \n",
    "$$\\mathbf{z} = encoder(\\mathbf{x})$$\n",
    "$$\\mathbf{\\tilde{x}} = decoder(\\mathbf{z})$$\n",
    "\n",
    "The goal is to train the AE, the goal is to minimize the reconstruction error. This error can be defined as the mean square error for instance : \n",
    "$$\\min||\\mathbf{\\tilde{x}}-\\mathbf{x}||^2$$ \n",
    "\n",
    "For this lab session, you can work with the MNIST dataset and we will train 4 different models:\n",
    "- A linear Endoder/Decoder\n",
    "- A non-linear Fully Connected Encoder/Decoder\n",
    "- A Convolutional Encoder/Decoder\n",
    "- A U-Net Encoder/Decoder \n",
    "\n",
    "More details and constraints will be given through the practical session. \n",
    "Program:\n",
    "1. Import Data and visualize the images \n",
    "2. Build a train/test wrapper\n",
    "3. Train a linear model and understand how the latent dimension affects the reconstruction\n",
    "4. Use the model to denoise\n",
    "5. Use the model for anomaly detection\n",
    "6. Train and use a Fully Connected model for denoising and anomaly detection\n",
    "7. Train and use a Convolutional model for denoising and anomaly detection\n",
    "\n",
    "\n",
    "First, we import the package required for the TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Library for numerical calculations\n",
    "import matplotlib.pyplot as plt # Library for plotting\n",
    "\n",
    "import math # Library for mathematical functions\n",
    "\n",
    "import torch # Library for tensor computations - for Deep Learning\n",
    "import torch.nn as nn # Neural Network module\n",
    "import torch.optim as optim # Optimization module\n",
    "from torchvision import datasets, transforms # Computer Vision module\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats=['retina']\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to check if there are gpu on this computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Device for tensor computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And functions that will be useful to:\n",
    "- Plot the reconstruction\n",
    "- Plot the data in the latent space\n",
    "- Print the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(model):\n",
    "    '''plot_result\n",
    "    Plot the first 5 images of the test set and their reconstructions\n",
    "    Input: \n",
    "        - model: the trained model\n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    first_outputs = model(first_batch_images.to(device))\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(5):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(first_batch_images[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        plt.title('Input')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.imshow(first_outputs[i].cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "        plt.title('Output')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def plotLatentScatter(encoder, classes=None):\n",
    "    '''plotLatentScatter\n",
    "    Plot the test dataset in the latent space of the encoder\n",
    "    Input:\n",
    "        - encoder: the encoder model\n",
    "        - classes: the classes to plot\n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    latent_numpy = []\n",
    "    labels_numpy = []\n",
    "    for images, labels in test_loader:\n",
    "        x = images.to(device)\n",
    "        latent_numpy.append(encoder(x).cpu().detach().numpy())\n",
    "        labels_numpy.append(labels.numpy())\n",
    "    if classes is None : \n",
    "        classes = range(10)\n",
    "    latent_numpy = np.concatenate(latent_numpy)\n",
    "    labels_numpy = np.concatenate(labels_numpy)\n",
    "    for c in classes:\n",
    "        plt.scatter(latent_numpy[labels_numpy==c,0],latent_numpy[labels_numpy==c,1],marker=\"o\",alpha=0.1,label=str(c))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def print_nparameters(model):\n",
    "    '''print_nparameters\n",
    "    Print the number of parameters of the model\n",
    "    Input:\n",
    "        - model: the model\n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    nparameters = 0\n",
    "    for parameter in model.parameters():\n",
    "        nparameters += parameter.numel()\n",
    "    print('Number of parameters:', nparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import Data and visualize the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "print('Train dataset:', train_dataset, \"\\n\")\n",
    "print('Test dataset:', test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = train_dataset.data[:5]\n",
    "samples_test = test_dataset.data[:5]\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    if i == 0:\n",
    "        plt.ylabel('Train', fontsize=14)\n",
    "    plt.imshow(samples_train[i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    if i == 0:\n",
    "        plt.ylabel('Test', fontsize=14)\n",
    "    plt.imshow(samples_test[i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build the dataloader: a function that cut the dataset in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch_images, first_batch_labels = next(iter(train_loader))\n",
    "print('First batch:', first_batch_images.shape, first_batch_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Wrapper for training and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to automatize the process of training and testing the model. \n",
    "\n",
    "To do so, we will define a function that will take as input the model, the loss function, the optimizer, the number of epochs, and the train and test loaders. The function will return the loss of the model during the training and testing phases. \n",
    "\n",
    "TODO:\n",
    "- Complete the AE_train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_eval(model, criterion):\n",
    "    '''AE_eval\n",
    "    Evaluate the model on the test set\n",
    "    Input:\n",
    "        - model: the trained model\n",
    "        - criterion: the loss function\n",
    "    Output:\n",
    "        - test_loss: the average loss on the test set\n",
    "    '''\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            test_loss += criterion(outputs, images).item()\n",
    "    return test_loss/len(test_loader)\n",
    "\n",
    "def AE_train(model, criterion, optimizer, epochs=30, plot = True,verbose=False, freq=10):\n",
    "    '''AE_train\n",
    "    Train the model\n",
    "    Input:\n",
    "        - model: the model to train\n",
    "        - criterion: the loss function\n",
    "        - optimizer: the optimization algorithm\n",
    "        - epochs: the number of epochs\n",
    "        - plot: if True, plot the train and test losses\n",
    "        - verbose: if True, print the losses\n",
    "        - freq: frequency of printing the losses\n",
    "    Output:\n",
    "        - train_losses: the train losses\n",
    "        - test_losses: the test losses\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('Start training...')\n",
    "    train_losses=[]\n",
    "    test_losses=[AE_eval(model, criterion)] # Evaluate the model on the test set\n",
    "    for e in range(epochs):\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            # Complete code here\n",
    "            # Your code must include the following lines:\n",
    "            # - Set the model to train mode\n",
    "            # - Move the images to the device\n",
    "            # - Reset the optimizer\n",
    "            # - Forward pass\n",
    "            # - Compute the loss\n",
    "            # - Backward pass\n",
    "            # - Update the weights\n",
    "            # - Print the losses if verbose is True\n",
    "            # - Evaluate the model at the end of each epoch\n",
    "\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(train_losses, label='Train loss')\n",
    "        plt.plot([e*batch_idx for e in range(e+2)], test_losses, label='Test loss', marker='o', linewidth=0.0)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    return train_losses, test_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Linear Auto-encoder \n",
    "\n",
    "The basic idea is to have a linear transformation for both the encoder and decoder. \n",
    "For the output activation, we can use the sigmoid, since we know that the images are in greyscale, and the pixel values are between $0$ and $1$. \n",
    "\n",
    "The only hyperparameter we have is the dimension of the latent space: $h_{\\mathrm{dim}} < 784$.\n",
    "\n",
    "## 3.1 First model \n",
    "\n",
    "**TODO**:\n",
    "- Write a class for the encoder\n",
    "- Test it on some images as sanity-check using the *plot_result* function \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write the class \n",
    "class AElin(nn.Module):\n",
    "    '''AElin\n",
    "    Autoencoder with linear layers\n",
    "    Parameters:\n",
    "        - hdim: the dimension of the hidden layer\n",
    "    '''\n",
    "    def __init__(self,hdim = 2):\n",
    "        super().__init__()\n",
    "        # Use the function nn.Sequential to define the encoder and decoder\n",
    "        self.encoder = ... # Complete code here \n",
    "        self.decoder = ... # Complete code here\n",
    "    \n",
    "    def encoder_function(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = decoded.reshape(x.size(0), 1, 28, 28)\n",
    "        return decoded\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and test it \n",
    "AE = AElin().to(device)\n",
    "print_nparameters(AE)\n",
    "plot_result(AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** \n",
    "- Train your model and plot the loss during training for 5 epochs.\n",
    "- Observe the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "AE = AElin().to(device)\n",
    "print_nparameters(AE)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "lossAE = ... # Complete code here\n",
    "\n",
    "# Using an Adam Optimizer \n",
    "optimizer = ... # Complete code here\n",
    "\n",
    "AE_train( ... ) # Complete code here\n",
    "\n",
    "\n",
    "plot_result(AE)\n",
    "plotLatentScatter(AE.encoder_function, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "plotLatentScatter(AE.encoder_function, classes=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Try different hyperpameters\n",
    "\n",
    "**TODO**\n",
    "- Try different latent dimension: 2, 10, 20 50, 100\n",
    "- Try different learning rates: 1e-1, 1e-2, 1e-3, 1e-4, 1e-5 with $h_{dim}=20$\n",
    "\n",
    "For each try, plot the reconstructions result and the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Dimension \n",
    "\n",
    "... # Complete code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rates\n",
    "\n",
    "... # Complete code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Use the AE as a denoising model\n",
    "\n",
    "We will see in this section how we can use the a AutoEncoder a denoising model. Compare the performance of an excellent model and a decent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "AE_train( ... ) # Complete code here\n",
    "\n",
    "images = first_batch_images[:1]\n",
    "sigmas = [1e-2,2e-2, 5e-2, 1e-1,3e-1, 5e-1]\n",
    "plt.figure(figsize=(8, 4))\n",
    "for k, sigma in enumerate(sigmas):\n",
    "    plt.subplot(3,len(sigmas),  k+1)\n",
    "    if k==0:\n",
    "        plt.ylabel('Original', fontsize=14)\n",
    "    plt.imshow(images.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    noise = torch.randn(1, 1, 28, 28) * sigma\n",
    "    plt.subplot(3, len(sigmas), k+1+len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Noisy', fontsize=14)\n",
    "    plt.imshow((noise+images).cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'noise: {sigma:.0e}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(3, len(sigmas), k+1+2*len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Reconstructed', fontsize=14)\n",
    "    plt.imshow(AE((images+noise).to(device)).cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "AE_train( ... ) # Complete code here\n",
    "\n",
    "images = first_batch_images[:1]\n",
    "sigmas = [1e-2,2e-2, 5e-2, 1e-1,3e-1, 5e-1]\n",
    "plt.figure(figsize=(8, 4))\n",
    "for k, sigma in enumerate(sigmas):\n",
    "\n",
    "    plt.subplot(3,len(sigmas),  k+1)\n",
    "    if k==0:\n",
    "        plt.ylabel('Original', fontsize=14)\n",
    "    plt.imshow(images.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    noise = torch.randn(1, 1, 28, 28) * sigma\n",
    "    plt.subplot(3, len(sigmas), k+1+len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Noisy', fontsize=14)\n",
    "    plt.imshow((noise+images).cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'noise: {sigma:.0e}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(3, len(sigmas), k+1+2*len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Reconstructed', fontsize=14)\n",
    "    plt.imshow(AE((images+noise).to(device)).cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Anomaly detection\n",
    "\n",
    "Autoencoders can learn to represent the data in a latent representation space and to reconstruct the data from this compressed representation. One possible application of AE is Anomaly detection. The method is simple: \n",
    "- if you encode and decode an image similar to the training data, the reconstruction loss should be low, while \n",
    "- if you do the same with an image that differs from the training set, the loss should be higher. \n",
    "\n",
    "We will use a strong model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "AE_train( ... ); # Complete code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test compare data dstribution we can compare:\n",
    "- the loss on the training data \n",
    "- the loss on the training with different anomalies\n",
    "    - Transpositions\n",
    "    - Artifacts\n",
    "    - Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anomaly(input_data, mode='transpose'):\n",
    "    '''make_anomaly\n",
    "    Detect anomalies in the input data using the model\n",
    "    Input:\n",
    "        - input_data: the input data\n",
    "        - mode: the mode for the anomaly detection among ['transpose', 'artifacts', 'mixing']\n",
    "    Output:\n",
    "        - anomalies: the pertubed images\n",
    "    '''\n",
    "    if mode == 'transpose':\n",
    "        anomalies = input_data.clone()\n",
    "        anomalies = anomalies.permute(0, 1, 3, 2)\n",
    "\n",
    "    elif mode == 'artifacts':\n",
    "        anomalies = input_data.clone()\n",
    "        anomalies[:, :, 10:20, 10:20] = 1\n",
    "    elif mode == 'mixing':\n",
    "        anomalies = input_data.clone()\n",
    "        anomalies[:, :, 10:15, 10:15] = input_data[:, :, 15:20, 15:20]\n",
    "        anomalies[:, :, 15:20, 15:20] = input_data[:, :, 10:15, 10:15]\n",
    "        anomalies[:, :, 10:15, 15:20] = input_data[:, :, 15:20, 10:15]\n",
    "        anomalies[:, :, 15:20, 10:15] = input_data[:, :, 10:15, 15:20]  \n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = make_anomaly(first_batch_images, mode='mixing')\n",
    "recons = AE(first_batch_images.to(device))\n",
    "recons_a = AE(anomalies.to(device))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    image = first_batch_images[i].cpu().numpy().reshape(28, 28)\n",
    "    if i == 0:\n",
    "        plt.ylabel('Original', fontsize=14)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(4, 5, i+6) \n",
    "    recon = recons[i].cpu().detach().numpy().reshape(28, 28) \n",
    "    if i == 0:\n",
    "        plt.ylabel('Recons', fontsize=14)\n",
    "    plt.title(f'MSE: {np.linalg.norm(image - recon):.2f}', fontsize=14)\n",
    "    plt.imshow(recon, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(4, 5, i+11)\n",
    "    anomaly = anomalies[i].detach().numpy().reshape(28, 28)\n",
    "    if i == 0:\n",
    "        plt.ylabel('Anomaly', fontsize=14)\n",
    "    plt.imshow(anomaly, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(4, 5, i+16)\n",
    "    recon = recons_a[i].cpu().detach().numpy().reshape(28, 28)\n",
    "    if i == 0:\n",
    "        plt.ylabel('Recons', fontsize=14)\n",
    "    plt.title(f'MSE: {np.linalg.norm(anomaly - recon):.2f}', fontsize=14)\n",
    "    plt.imshow(recon, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "- code a function that compute these two histograms and plot these\n",
    "- check if the histogram differs for the different type of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect_anomalies(model,loader, mode='transpose'):\n",
    "    '''detect_anomalies\n",
    "    Plot the histogram of the MSE of the anomalies on the test  set \n",
    "    Input:\n",
    "        - model: the trained model\n",
    "        - mode: the mode for the anomaly detection among ['transpose', 'artifacts', 'mixing']\n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    ... # Complete code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_anomalies(AE, train_loader, mode='transpose')\n",
    "detect_anomalies(AE, train_loader, mode='artifacts')\n",
    "detect_anomalies(AE, train_loader, mode='mixing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Full connected autoencoder\n",
    "\n",
    "We can increase the depth of the AE: \n",
    "- the encoder is composed of a first linear transformation, followed by a non-linearity (ReLU) and a second linear transformation. \n",
    "- the decoder performs the symmetric operations. \n",
    "\n",
    "As dimensions we can consider as a first choice : 784 ==> 256 ==> $h_{dim}=2$ ==> 256 ==> 784. \n",
    "\n",
    "**TODO**\n",
    "- Write the class for such AE and test with the basic configuration (see above) first with $h_{dim}=2$, then with an higher  $h_{dim}<784$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAE(nn.Module):\n",
    "    def __init__(self,hdim1=256,hdim2=2):\n",
    "        super().__init__()\n",
    "        ... # Complete code here\n",
    "    \n",
    "    def encoder_function(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = decoded.reshape(x.size(0), 1, 28, 28)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAE = ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "_ = AE_train( ... ) # Complete code here\n",
    "plot_result(SAE)\n",
    "plotLatentScatter(SAE.encoder_function, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "plotLatentScatter(SAE.encoder_function, classes=[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAE = ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "_ = AE_train( ... ) # Complete code here\n",
    "plot_result(SAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the denoising and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = first_batch_images[:1]\n",
    "sigmas = [1e-2,2e-2, 5e-2, 1e-1,3e-1, 5e-1]\n",
    "plt.figure(figsize=(8, 4))\n",
    "for k, sigma in enumerate(sigmas):\n",
    "\n",
    "    plt.subplot(3,len(sigmas),  k+1)\n",
    "    if k==0:\n",
    "        plt.ylabel('Original', fontsize=14)\n",
    "    plt.imshow(images.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    noise = torch.randn(1, 1, 28, 28) * sigma\n",
    "    plt.subplot(3, len(sigmas), k+1+len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Noisy', fontsize=14)\n",
    "    plt.imshow((noise+images).cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'noise: {sigma:.0e}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(3, len(sigmas), k+1+2*len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Reconstructed', fontsize=14)\n",
    "    plt.imshow(SAE((images+noise).to(device)).cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_anomalies(SAE, train_loader, mode='transpose')\n",
    "detect_anomalies(SAE, train_loader, mode='artifacts')\n",
    "detect_anomalies(SAE, train_loader, mode='mixing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Convolutional Autoencoder\n",
    "\n",
    "**TODO**:\n",
    "Implement a CNN Autoencoder with the following architecture:\n",
    "- Encoder:\n",
    "    - Conv2d(1, 16, kernel_size=3, stride=2, padding=1) ==> ReLU ==> Conv2d(16, 32, kernel_size=3, stride=2, padding=1) ==> ReLU ==> Conv2d(32, $h_{dim}$, kernel_size=7)\n",
    "- Decoder:\n",
    "    - ConvTranspose2d($h_{dim}$, 32, kernel_size=7) ==> ReLU ==> ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1) ==> ReLU ==> ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1) ==> Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, hdim=2):\n",
    "        super().__init__()\n",
    "        ... # Complete code here\n",
    "    \n",
    "    def encoder_function(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAE = ConvAE().to(device)\n",
    "print_nparameters(CAE)\n",
    "plot_result(CAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAE =  ... # Complete code here\n",
    "optimizer = ... # Complete code here\n",
    "_ = AE_train( ... ) # Complete code here\n",
    "plot_result(CAE)\n",
    "plotLatentScatter(CAE.encoder_function, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "plotLatentScatter(CAE.encoder_function, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = first_batch_images[:1]\n",
    "sigmas = [1e-2,2e-2, 5e-2, 1e-1,3e-1, 5e-1]\n",
    "plt.figure(figsize=(8, 4))\n",
    "for k, sigma in enumerate(sigmas):\n",
    "\n",
    "    plt.subplot(3,len(sigmas),  k+1)\n",
    "    if k==0:\n",
    "        plt.ylabel('Original', fontsize=14)\n",
    "    plt.imshow(images.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    noise = torch.randn(1, 1, 28, 28) * sigma\n",
    "    plt.subplot(3, len(sigmas), k+1+len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Noisy', fontsize=14)\n",
    "    plt.imshow((noise+images).cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'noise: {sigma:.0e}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(3, len(sigmas), k+1+2*len(sigmas))\n",
    "    if k == 0:\n",
    "        plt.ylabel('Reconstructed', fontsize=14)\n",
    "    plt.imshow(CAE((images+noise).to(device)).cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_anomalies(CAE, train_loader, mode='transpose')\n",
    "detect_anomalies(CAE, train_loader, mode='artifacts')\n",
    "detect_anomalies(CAE, train_loader, mode='mixing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
